{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch import optim, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "if torch.cuda.is_available() :\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset) :\n",
    "\n",
    "    def __init__(self, transform) :\n",
    "        self.root_path = 'PACS/kfold/'\n",
    "\n",
    "        # Listing the domains\n",
    "        self.domains = os.listdir(self.root_path)\n",
    "\n",
    "        # Listing the classes \n",
    "        self.classes = os.listdir(self.root_path+'cartoon')\n",
    "\n",
    "        # Transformations\n",
    "        self.transforms = transform\n",
    "\n",
    "        self.images = []\n",
    "        self.domains_y = []\n",
    "        self.classes_y = []\n",
    "\n",
    "        for i_dom, domain in enumerate(self.domains) :\n",
    "            for i_cla, cla in enumerate(self.classes) :\n",
    "                for image in os.listdir(self.root_path+domain+'/'+cla) :\n",
    "                    # Finding image path\n",
    "                    image_path = self.root_path+domain+'/'+cla+'/'+image\n",
    "                    img = cv2.imread(image_path)\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    self.images.append(img)\n",
    "\n",
    "                    # One hot encoding domain\n",
    "                    domainVector = np.zeros(5)\n",
    "                    domainVector[-1] = 1\n",
    "                    domainVector[i_dom] = 1\n",
    "                    self.domains_y.append(domainVector)\n",
    "\n",
    "                    # One hot encoding class\n",
    "                    classVector = np.zeros(7)\n",
    "                    classVector[i_cla] = 1\n",
    "                    self.classes_y.append(classVector)\n",
    "\n",
    "        self.images = np.array(self.images)\n",
    "        self.domains_y = np.array(self.domains_y)\n",
    "        self.classes_y = np.array(self.classes_y)\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "\n",
    "        return self.transforms(self.images[index].astype('float')/255), self.domains_y[index], self.classes_y[index]\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Resize(256),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [6000, 1000, 2991])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train' : train_dataloader,\n",
    "    'val' : val_dataloader,\n",
    "    'test' : test_dataloader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train' : 6000,\n",
    "    'val': 1000,\n",
    "    'test' : 2991\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, epochs=1):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 0.0\n",
    "    best_acc = 0\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        print(f\"Epoch {ep}/{epochs-1}\")\n",
    "        print(\"-\"*10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "                \n",
    "            for images, domain, labels in tqdm(dataloaders[phase]):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                _, labels_list = torch.max(labels, 1)\n",
    "                labels_list = labels_list.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(images.float())\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_corrects += torch.sum(preds == labels_list)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print(f\"{phase} Loss:{epoch_loss:.4f} Acc:{epoch_acc:.4f}\")\n",
    "            \n",
    "            if phase == 'val':\n",
    "                if ep == 0:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                else:\n",
    "                    if epoch_loss < best_loss:\n",
    "                        best_loss = epoch_loss\n",
    "                        best_acc = epoch_acc\n",
    "                        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    \n",
    "    print(f'Training complete in {time_elapsed // 60}m {time_elapsed % 60}s')\n",
    "    print(f'Best val loss: {best_loss:.4f}')\n",
    "    print(f'Best acc: {best_acc}')\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Changing the last layer of the model\n",
    "model.fc = nn.Linear(512, 7)\n",
    "\n",
    "model = nn.Sequential(model, \n",
    "                        nn.Softmax(1))\n",
    "\n",
    "# To GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Defining loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Defining optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [14:49<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss:1.5536 Acc:0.6487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:45<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss:1.2941 Acc:0.8780\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [12:27<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss:1.3601 Acc:0.8212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss:1.2690 Acc:0.8970\n",
      "\n",
      "Training complete in 28.0m 39.850985288619995s\n",
      "Best val loss: 1.2690\n",
      "Best acc: 0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 748/748 [02:10<00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the test dataset : 0.8963557481765747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "running_correct = 0\n",
    "total = 0\n",
    "\n",
    "for img, dom, cla in tqdm(test_dataloader) :\n",
    "  img = img.to(device)\n",
    "  dom = dom.to(device)\n",
    "  cla = cla.to(device)\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  pred = model(img.float())\n",
    "\n",
    "  _, pred_list = torch.max(pred, 1)\n",
    "  pred_list = pred_list.to(device)\n",
    "\n",
    "  _, cla_list = torch.max(cla, 1)\n",
    "  cla_list = cla_list.to(device)\n",
    "\n",
    "  running_correct += torch.sum(pred_list == cla_list)\n",
    "\n",
    "print(f'Accuracy of the test dataset : {running_correct/len(test_dataset)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f71267cb382aad57a1826fa66d359ca32b8120787d9413fb646158b5b727d965"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
