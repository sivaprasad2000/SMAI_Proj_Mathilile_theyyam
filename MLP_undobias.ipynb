{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXy1DbnM_DL_",
        "outputId": "59fb0483-eef5-4bea-d6b7-b3ac881a361c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqJB51Vz_biN",
        "outputId": "0929ca1a-f903-4454-b7e2-a2e9c0f17fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Proj\n"
          ]
        }
      ],
      "source": [
        "cd gdrive/MyDrive/Proj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEqL_8ZJ_Cpb"
      },
      "source": [
        "Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3UbZ6eQb_Cpf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch import optim, nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ipVqjewy_Cpg"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "\n",
        "if torch.cuda.is_available() :\n",
        "    device = 'cuda'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7shgQss_Cph"
      },
      "source": [
        "Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9g-sweAU_Cph"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset) :\n",
        "\n",
        "    def __init__(self, transform) :\n",
        "        self.root_path = 'PACS/kfold/'\n",
        "\n",
        "        # Listing the domains\n",
        "        self.domains = os.listdir(self.root_path)\n",
        "\n",
        "        # Listing the classes \n",
        "        self.classes = os.listdir(self.root_path+'cartoon')\n",
        "\n",
        "        # Transformations\n",
        "        self.transforms = transform\n",
        "\n",
        "        self.images = []\n",
        "        self.domains_y = []\n",
        "        self.classes_y = []\n",
        "\n",
        "        for i_dom, domain in enumerate(self.domains) :\n",
        "            for i_cla, cla in enumerate(self.classes) :\n",
        "                for image in os.listdir(self.root_path+domain+'/'+cla) :\n",
        "                    # Finding image path\n",
        "                    image_path = self.root_path+domain+'/'+cla+'/'+image\n",
        "                    img = cv2.imread(image_path)\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    self.images.append(img)\n",
        "\n",
        "                    # One hot encoding domain\n",
        "                    domainVector = np.zeros(5)\n",
        "                    domainVector[-1] = 1\n",
        "                    domainVector[i_dom] = 1\n",
        "                    self.domains_y.append(domainVector)\n",
        "\n",
        "                    # One hot encoding class\n",
        "                    classVector = np.zeros(7)\n",
        "                    classVector[i_cla] = 1\n",
        "                    self.classes_y.append(classVector)\n",
        "\n",
        "        self.images = np.array(self.images)\n",
        "        self.domains_y = np.array(self.domains_y)\n",
        "        self.classes_y = np.array(self.classes_y)\n",
        "\n",
        "        self.domains_y = torch.Tensor(self.domains_y)\n",
        "        self.classes_y = torch.Tensor(self.classes_y)\n",
        "\n",
        "    def __getitem__(self, index) :\n",
        "\n",
        "        return self.transforms(self.images[index].astype('float')/255), self.domains_y[index], self.classes_y[index]\n",
        "\n",
        "    def __len__(self) :\n",
        "        return len(self.images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vO8Fkkp_Cpi"
      },
      "source": [
        "Defining transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XKU6oKSD_Cpi"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Resize(50),\n",
        "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YXNEoG3e_Cpj"
      },
      "outputs": [],
      "source": [
        "dataset = ImageDataset(transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NA1wbAYz_Cpj"
      },
      "outputs": [],
      "source": [
        "# Train and test split\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [6000, 1000, 2991])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YWttx5bv_Cpk"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=4, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ef9NApY7_Cpl"
      },
      "outputs": [],
      "source": [
        "dataloaders = {\n",
        "    'train' : train_dataloader,\n",
        "    'val' : val_dataloader,\n",
        "    'test' : test_dataloader\n",
        "}\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train' : 6000,\n",
        "    'val': 1000,\n",
        "    'test' : 2991\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "niuV-4S6_Cpm"
      },
      "outputs": [],
      "source": [
        "def getWeightsAndBiases(in_size, out_size, no_domains) :\n",
        "\n",
        "    weight_mat = torch.zeros(out_size, in_size, no_domains+1)\n",
        "    bias_mat = torch.zeros(out_size, no_domains+1)\n",
        "\n",
        "    for i in range(no_domains+1) :\n",
        "        linMod = nn.Linear(in_size, out_size)\n",
        "\n",
        "        weight = linMod.weight.detach()\n",
        "        bias = linMod.bias.detach()\n",
        "\n",
        "        if not(i == no_domains) :\n",
        "          weight_mat[:, :, i] = weight/no_domains\n",
        "          bias_mat[:, i] = bias/no_domains\n",
        "\n",
        "    return weight_mat, bias_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WLTkNjo-_Cpm"
      },
      "outputs": [],
      "source": [
        "# Initializing the weights and biases\n",
        "\n",
        "weight1, bias1 = getWeightsAndBiases(3*50*50, 2048, 4)\n",
        "weight2, bias2 = getWeightsAndBiases(2048, 2048, 4)\n",
        "weight3, bias3 = getWeightsAndBiases(2048, 1024, 4)\n",
        "weight4, bias4 = getWeightsAndBiases(1024, 7, 4)\n",
        "\n",
        "weight1 = weight1.to(device)\n",
        "weight2 = weight2.to(device)\n",
        "weight3 = weight3.to(device)\n",
        "weight4 = weight4.to(device)\n",
        "\n",
        "bias1 = bias1.to(device)\n",
        "bias2 = bias2.to(device)\n",
        "bias3 = bias3.to(device)\n",
        "bias4 = bias4.to(device)\n",
        "\n",
        "weight1.requires_grad = True\n",
        "weight2.requires_grad = True\n",
        "weight3.requires_grad = True\n",
        "weight4.requires_grad = True\n",
        "\n",
        "bias1.requires_grad = True\n",
        "bias2.requires_grad = True\n",
        "bias3.requires_grad = True\n",
        "bias4.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DJW4Obmy_Cpm"
      },
      "outputs": [],
      "source": [
        "def MLPModelUndoBias(X, dom_vec) :\n",
        "    \n",
        "    x_flattened = X.reshape(-1, 3*50*50)\n",
        "\n",
        "    # Calculating the current weights and biases by taking inner product\n",
        "    weight_1_curr = torch.inner(weight1, dom_vec)\n",
        "    weight_2_curr = torch.inner(weight2, dom_vec)\n",
        "    weight_3_curr = torch.inner(weight3, dom_vec)\n",
        "    weight_4_curr = torch.inner(weight4, dom_vec)\n",
        "\n",
        "    bias_1_curr = torch.inner(bias1, dom_vec)\n",
        "    bias_2_curr = torch.inner(bias2, dom_vec)\n",
        "    bias_3_curr = torch.inner(bias3, dom_vec)\n",
        "    bias_4_curr = torch.inner(bias4, dom_vec)\n",
        "\n",
        "    out = x_flattened\n",
        "\n",
        "    out = (x_flattened@(weight_1_curr.T))+bias_1_curr\n",
        "    out = F.relu(out)\n",
        "    out = (out@(weight_2_curr.T))+bias_2_curr\n",
        "    out = F.relu(out)\n",
        "    out = (out@(weight_3_curr.T))+bias_3_curr\n",
        "    out = F.relu(out)\n",
        "    out = (out@(weight_4_curr.T))+bias_4_curr\n",
        "    out = F.softmax(out, 1)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnN89NlF_Cpn",
        "outputId": "fa46d390-0f74-4c49-db8e-50d7c25f9199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [09:50<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9 | Loss : 1.9451797008514404 | Accuracy : 0.16133333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [09:49<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9 | Loss : 1.9436601400375366 | Accuracy : 0.17866666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [09:50<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/9 | Loss : 1.9416334629058838 | Accuracy : 0.185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [09:50<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/9 | Loss : 1.9332275390625 | Accuracy : 0.20166666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [09:49<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/9 | Loss : 1.9276213645935059 | Accuracy : 0.2005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [09:49<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/9 | Loss : 1.9263132810592651 | Accuracy : 0.21633333333333332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [09:49<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/9 | Loss : 1.9243115186691284 | Accuracy : 0.21766666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [09:49<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/9 | Loss : 1.9210090637207031 | Accuracy : 0.218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [09:49<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/9 | Loss : 1.9186251163482666 | Accuracy : 0.21616666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [09:49<00:00, 10.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/9 | Loss : 1.915515661239624 | Accuracy : 0.21566666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "lr = 0.001\n",
        "\n",
        "# Writing the training loop\n",
        "for e in range(epochs) :\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    \n",
        "    for img, dom, cla in tqdm(train_dataset) :\n",
        "\n",
        "        img = img.to(device)\n",
        "        dom = dom.to(device)\n",
        "        cla = cla.to(device)\n",
        "        \n",
        "        # Finding prediction\n",
        "        pred = MLPModelUndoBias(img.float(), dom.float())\n",
        "\n",
        "        # Calculating loss\n",
        "        loss = F.cross_entropy(pred, cla.reshape(-1, 7))\n",
        "\n",
        "        running_loss += loss\n",
        "\n",
        "        pred_class = torch.argmax(pred)\n",
        "        actual_class = torch.argmax(cla)\n",
        "\n",
        "        if(pred_class == actual_class) :\n",
        "            running_correct += 1\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient descent\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            weight1 -= weight1.grad * lr\n",
        "            weight2 -= weight2.grad * lr\n",
        "            weight3 -= weight3.grad * lr\n",
        "            weight4 -= weight4.grad * lr\n",
        "\n",
        "            bias1 -= bias1.grad * lr\n",
        "            bias2 -= bias2.grad * lr\n",
        "            bias3 -= bias3.grad * lr\n",
        "            bias4 -= bias4.grad * lr\n",
        "\n",
        "            weight1.grad.zero_()\n",
        "            weight2.grad.zero_()\n",
        "            weight3.grad.zero_()\n",
        "            weight4.grad.zero_()\n",
        "\n",
        "            bias1.grad.zero_()\n",
        "            bias2.grad.zero_()\n",
        "            bias3.grad.zero_()\n",
        "            bias4.grad.zero_()\n",
        "        \n",
        "    print(f'Epoch {e}/{epochs-1} | Loss : {running_loss/len(train_dataset)} | Accuracy : {running_correct/len(train_dataset)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I193brBx_kw2"
      },
      "outputs": [],
      "source": [
        "# Now extracting the domain agnostic model\n",
        "def domainAgnosticModel(X) :\n",
        "  x_flattened = X.reshape(-1, 3*50*50)\n",
        "\n",
        "  # Calculating the current weights and biases by taking inner product\n",
        "  weight_1_curr = weight1[:, :, -1]\n",
        "  weight_2_curr = weight2[:, :, -1]\n",
        "  weight_3_curr = weight3[:, :, -1]\n",
        "  weight_4_curr = weight4[:, :, -1]\n",
        "\n",
        "  bias_1_curr = bias1[:, -1]\n",
        "  bias_2_curr = bias2[:, -1]\n",
        "  bias_3_curr = bias3[:, -1]\n",
        "  bias_4_curr = bias4[:, -1]\n",
        "\n",
        "  out = x_flattened\n",
        "\n",
        "  out = (x_flattened@(weight_1_curr.T))+bias_1_curr\n",
        "  out = F.relu(out)\n",
        "  out = (out@(weight_2_curr.T))+bias_2_curr\n",
        "  out = F.relu(out)\n",
        "  out = (out@(weight_3_curr.T))+bias_3_curr\n",
        "  out = F.relu(out)\n",
        "  out = (out@(weight_4_curr.T))+bias_4_curr\n",
        "  out = F.softmax(out, 1)\n",
        "\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EEnRCdTcvMZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4cfb82-2ac3-4995-bf06-3095c9b524c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 748/748 [00:10<00:00, 71.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the test dataset : 0.21330657601356506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Testing loop\n",
        "running_correct = 0\n",
        "total = 0\n",
        "\n",
        "for img, dom, cla in tqdm(test_dataloader) :\n",
        "  img = img.to(device)\n",
        "  dom = dom.to(device)\n",
        "  cla = cla.to(device)\n",
        "\n",
        "  pred = domainAgnosticModel(img.float())\n",
        "\n",
        "  _, pred_list = torch.max(pred, 1)\n",
        "  pred_list = pred_list.to(device)\n",
        "\n",
        "  _, cla_list = torch.max(cla, 1)\n",
        "  cla_list = cla_list.to(device)\n",
        "\n",
        "  running_correct += torch.sum(pred_list == cla_list)\n",
        "\n",
        "print(f'Accuracy of the test dataset : {running_correct/len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-ph0BSMvhvE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MLP_undobias.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f71267cb382aad57a1826fa66d359ca32b8120787d9413fb646158b5b727d965"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}