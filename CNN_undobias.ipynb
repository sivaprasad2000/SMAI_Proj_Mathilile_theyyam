{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEqL_8ZJ_Cpb"
      },
      "source": [
        "Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3UbZ6eQb_Cpf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch import optim, nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ipVqjewy_Cpg"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "\n",
        "if torch.cuda.is_available() :\n",
        "    device = 'cuda'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7shgQss_Cph"
      },
      "source": [
        "Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9g-sweAU_Cph"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset) :\n",
        "\n",
        "    def __init__(self, transform) :\n",
        "        self.root_path = 'PACS/kfold/'\n",
        "\n",
        "        # Listing the domains\n",
        "        self.domains = os.listdir(self.root_path)\n",
        "\n",
        "        # Listing the classes \n",
        "        self.classes = os.listdir(self.root_path+'cartoon')\n",
        "\n",
        "        # Transformations\n",
        "        self.transforms = transform\n",
        "\n",
        "        self.images = []\n",
        "        self.domains_y = []\n",
        "        self.classes_y = []\n",
        "\n",
        "        for i_dom, domain in enumerate(self.domains) :\n",
        "            for i_cla, cla in enumerate(self.classes) :\n",
        "                for image in os.listdir(self.root_path+domain+'/'+cla) :\n",
        "                    # Finding image path\n",
        "                    image_path = self.root_path+domain+'/'+cla+'/'+image\n",
        "                    img = cv2.imread(image_path)\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    self.images.append(img)\n",
        "\n",
        "                    # One hot encoding domain\n",
        "                    domainVector = np.zeros(5)\n",
        "                    domainVector[-1] = 1\n",
        "                    domainVector[i_dom] = 1\n",
        "                    self.domains_y.append(domainVector)\n",
        "\n",
        "                    # One hot encoding class\n",
        "                    classVector = np.zeros(7)\n",
        "                    classVector[i_cla] = 1\n",
        "                    self.classes_y.append(classVector)\n",
        "\n",
        "        self.images = np.array(self.images)\n",
        "        self.domains_y = np.array(self.domains_y)\n",
        "        self.classes_y = np.array(self.classes_y)\n",
        "\n",
        "        self.domains_y = torch.Tensor(self.domains_y)\n",
        "        self.classes_y = torch.Tensor(self.classes_y)\n",
        "\n",
        "    def __getitem__(self, index) :\n",
        "\n",
        "        return self.transforms(self.images[index].astype('float')/255), self.domains_y[index], self.classes_y[index]\n",
        "\n",
        "    def __len__(self) :\n",
        "        return len(self.images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vO8Fkkp_Cpi"
      },
      "source": [
        "Defining transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XKU6oKSD_Cpi"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YXNEoG3e_Cpj"
      },
      "outputs": [],
      "source": [
        "dataset = ImageDataset(transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NA1wbAYz_Cpj"
      },
      "outputs": [],
      "source": [
        "# Train and test split\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [6000, 1000, 2991])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YWttx5bv_Cpk"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=4, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ef9NApY7_Cpl"
      },
      "outputs": [],
      "source": [
        "dataloaders = {\n",
        "    'train' : train_dataloader,\n",
        "    'val' : val_dataloader,\n",
        "    'test' : test_dataloader\n",
        "}\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train' : 6000,\n",
        "    'val': 1000,\n",
        "    'test' : 2991\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getWeightsAndBiasesCNN(in_dim, out_dim, kernel_size, no_domains) :\n",
        "\n",
        "    weights = torch.zeros(out_dim, in_dim, kernel_size, kernel_size, no_domains+1)\n",
        "    biases = torch.zeros(out_dim, no_domains+1)\n",
        "\n",
        "    for i in range(no_domains+1) :\n",
        "        conv_layer = nn.Conv2d(in_dim, out_dim, kernel_size)\n",
        "\n",
        "        weights[:, :, :, :, i] = conv_layer.state_dict()['weight']\n",
        "        biases[:, i] = conv_layer.state_dict()['bias']\n",
        "    \n",
        "    return weights, biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getWeightsAndBiasesDense(in_size, out_size, no_domains) :\n",
        "\n",
        "    weight_mat = torch.zeros(out_size, in_size, no_domains+1)\n",
        "    bias_mat = torch.zeros(out_size, no_domains+1)\n",
        "\n",
        "    for i in range(no_domains+1) :\n",
        "        linMod = nn.Linear(in_size, out_size)\n",
        "\n",
        "        weight = linMod.weight.detach()\n",
        "        bias = linMod.bias.detach()\n",
        "\n",
        "        if not(i == no_domains) :\n",
        "          weight_mat[:, :, i] = weight/no_domains\n",
        "          bias_mat[:, i] = bias/no_domains\n",
        "\n",
        "    return weight_mat, bias_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WLTkNjo-_Cpm"
      },
      "outputs": [],
      "source": [
        "# Initializing the weights and biases\n",
        "\n",
        "weight1, bias1 = getWeightsAndBiasesCNN(3, 96, 11, 4)\n",
        "\n",
        "# Maxpool here\n",
        "\n",
        "weight2, bias2 = getWeightsAndBiasesCNN(96, 256, 5, 4)\n",
        "\n",
        "# Maxpool here\n",
        "\n",
        "weight3, bias3 = getWeightsAndBiasesCNN(256, 384, 3, 4)\n",
        "weight4, bias4 = getWeightsAndBiasesCNN(384, 384, 3, 4)\n",
        "weight5, bias5 = getWeightsAndBiasesCNN(384, 256, 3, 4)\n",
        "\n",
        "# Maxpool here\n",
        "# Dropout here\n",
        "\n",
        "weight6, bias6 = getWeightsAndBiasesDense(256*6*6, 4096, 4)\n",
        "\n",
        "# Dropout here\n",
        "\n",
        "weight7, bias7 = getWeightsAndBiasesDense(4096, 4096, 4)\n",
        "weight8, bias8 = getWeightsAndBiasesDense(4096, 7, 4)\n",
        "\n",
        "weight1 = weight1.to(device)\n",
        "weight2 = weight2.to(device)\n",
        "weight3 = weight3.to(device)\n",
        "weight4 = weight4.to(device)\n",
        "weight5 = weight5.to(device)\n",
        "weight6 = weight6.to(device)\n",
        "weight7 = weight7.to(device)\n",
        "weight8 = weight8.to(device)\n",
        "\n",
        "bias1 = bias1.to(device)\n",
        "bias2 = bias2.to(device)\n",
        "bias3 = bias3.to(device)\n",
        "bias4 = bias4.to(device)\n",
        "bias5 = bias5.to(device)\n",
        "bias6 = bias6.to(device)\n",
        "bias7 = bias7.to(device)\n",
        "bias8 = bias8.to(device)\n",
        "\n",
        "weight1.requires_grad = True\n",
        "weight2.requires_grad = True\n",
        "weight3.requires_grad = True\n",
        "weight4.requires_grad = True\n",
        "weight5.requires_grad = True\n",
        "weight6.requires_grad = True\n",
        "weight7.requires_grad = True\n",
        "weight8.requires_grad = True\n",
        "\n",
        "bias1.requires_grad = True\n",
        "bias2.requires_grad = True\n",
        "bias3.requires_grad = True\n",
        "bias4.requires_grad = True\n",
        "bias5.requires_grad = True\n",
        "bias6.requires_grad = True\n",
        "bias7.requires_grad = True\n",
        "bias8.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DJW4Obmy_Cpm"
      },
      "outputs": [],
      "source": [
        "def CNNModelUndoBias(X, dom_vec, isTraining) :\n",
        "\n",
        "    # Using AlexNet architecture here\n",
        "\n",
        "    # Calculating the current weights and biases by taking inner product\n",
        "    weight1_curr = torch.inner(weight1, dom_vec)\n",
        "    weight2_curr = torch.inner(weight2, dom_vec)\n",
        "    weight3_curr = torch.inner(weight3, dom_vec)\n",
        "    weight4_curr = torch.inner(weight4, dom_vec)\n",
        "    weight5_curr = torch.inner(weight5, dom_vec)\n",
        "    weight6_curr = torch.inner(weight6, dom_vec)\n",
        "    weight7_curr = torch.inner(weight7, dom_vec)\n",
        "    weight8_curr = torch.inner(weight8, dom_vec)\n",
        "\n",
        "    bias1_curr = torch.inner(bias1, dom_vec)\n",
        "    bias2_curr = torch.inner(bias2, dom_vec)\n",
        "    bias3_curr = torch.inner(bias3, dom_vec)\n",
        "    bias4_curr = torch.inner(bias4, dom_vec)\n",
        "    bias5_curr = torch.inner(bias5, dom_vec)\n",
        "    bias6_curr = torch.inner(bias6, dom_vec)\n",
        "    bias7_curr = torch.inner(bias7, dom_vec)\n",
        "    bias8_curr = torch.inner(bias8, dom_vec)\n",
        "\n",
        "    out = X.reshape(-1, 3, 227, 227)\n",
        "\n",
        "    # Convolutional Layers\n",
        "\n",
        "    out = F.conv2d(out, weight1_curr, bias1_curr, 4)\n",
        "    out = F.relu(out)\n",
        "\n",
        "    out = F.max_pool2d(out, 3, 2)\n",
        "\n",
        "    out = F.conv2d(out, weight2_curr, bias2_curr, 1, 2)\n",
        "    out = F.relu(out)\n",
        "\n",
        "    out = F.max_pool2d(out, 3, 2)\n",
        "\n",
        "    out = F.conv2d(out, weight3_curr, bias3_curr, 1, 1)\n",
        "    out = F.relu(out)\n",
        "\n",
        "    out = F.conv2d(out, weight4_curr, bias4_curr, 1, 1)\n",
        "    out = F.relu(out)\n",
        "\n",
        "    out = F.conv2d(out, weight5_curr, bias5_curr, 1, 1)\n",
        "    out = F.relu(out)\n",
        "\n",
        "    out = F.max_pool2d(out, 3, 2)\n",
        "\n",
        "    out = F.dropout2d(out, 0.5, isTraining)\n",
        "\n",
        "    # Fully connected layers\n",
        "\n",
        "    out = out.reshape(1, -1)\n",
        "\n",
        "    out = F.linear(out, weight6_curr, bias6_curr)\n",
        "    out = F.relu(out)\n",
        "    out = F.dropout(out, 0.5, isTraining)\n",
        "    out = F.linear(out, weight7_curr, bias7_curr)\n",
        "    out = F.relu(out)\n",
        "    out = F.linear(out, weight8_curr, bias8_curr)\n",
        "    out = F.softmax(out, 1)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnN89NlF_Cpn",
        "outputId": "7a3ec514-a49a-49a1-e131-9944ef5ea6b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/6000 [00:07<12:27:16,  7.47s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1398380/575045816.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mweight4\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mweight4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mweight5\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mweight5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mweight6\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mweight6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mweight7\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mweight7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mweight8\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mweight8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 2\n",
        "lr = 0.001\n",
        "\n",
        "# Writing the training loop\n",
        "for e in range(epochs) :\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    \n",
        "    for img, dom, cla in tqdm(train_dataset) :\n",
        "\n",
        "        img = img.to(device)\n",
        "        dom = dom.to(device)\n",
        "        cla = cla.to(device)\n",
        "        \n",
        "        # Finding prediction\n",
        "        pred = CNNModelUndoBias(img.float(), dom.float(), True)\n",
        "\n",
        "        # Calculating loss\n",
        "        loss = F.cross_entropy(pred, cla.reshape(-1, 7))\n",
        "\n",
        "        running_loss += loss\n",
        "\n",
        "        pred_class = torch.argmax(pred)\n",
        "        actual_class = torch.argmax(cla)\n",
        "\n",
        "        if(pred_class == actual_class) :\n",
        "            running_correct += 1\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient descent\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            weight1 -= weight1.grad * lr\n",
        "            weight2 -= weight2.grad * lr\n",
        "            weight3 -= weight3.grad * lr\n",
        "            weight4 -= weight4.grad * lr\n",
        "            weight5 -= weight5.grad * lr\n",
        "            weight6 -= weight6.grad * lr\n",
        "            weight7 -= weight7.grad * lr\n",
        "            weight8 -= weight8.grad * lr\n",
        "\n",
        "            bias1 -= bias1.grad * lr\n",
        "            bias2 -= bias2.grad * lr\n",
        "            bias3 -= bias3.grad * lr\n",
        "            bias4 -= bias4.grad * lr\n",
        "            bias5 -= bias5.grad * lr\n",
        "            bias6 -= bias6.grad * lr\n",
        "            bias7 -= bias7.grad * lr\n",
        "            bias8 -= bias8.grad * lr\n",
        "\n",
        "            weight1.grad.zero_()\n",
        "            weight2.grad.zero_()\n",
        "            weight3.grad.zero_()\n",
        "            weight4.grad.zero_()\n",
        "            weight5.grad.zero_()\n",
        "            weight6.grad.zero_()\n",
        "            weight7.grad.zero_()\n",
        "            weight8.grad.zero_()\n",
        "\n",
        "            bias1.grad.zero_()\n",
        "            bias2.grad.zero_()\n",
        "            bias3.grad.zero_()\n",
        "            bias4.grad.zero_()\n",
        "            bias5.grad.zero_()\n",
        "            bias6.grad.zero_()\n",
        "            bias7.grad.zero_()\n",
        "            bias8.grad.zero_()\n",
        "        \n",
        "    print(f'Epoch {e}/{epochs-1} | Loss : {running_loss/len(train_dataset)} | Accuracy : {running_correct/len(train_dataset)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I193brBx_kw2"
      },
      "outputs": [],
      "source": [
        "# Now extracting the domain agnostic model\n",
        "def domainAgnosticModel(X) :\n",
        "\n",
        "  # Calculating the current weights and biases by taking inner product\n",
        "  weight1_curr = weight1[:, :, -1]\n",
        "  weight2_curr = weight2[:, :, -1]\n",
        "  weight3_curr = weight3[:, :, -1]\n",
        "  weight4_curr = weight4[:, :, -1]\n",
        "  weight5_curr = weight5[:, :, -1]\n",
        "  weight6_curr = weight6[:, :, -1]\n",
        "  weight7_curr = weight7[:, :, -1]\n",
        "  weight8_curr = weight8[:, :, -1]\n",
        "\n",
        "  bias1_curr = bias1[:, -1]\n",
        "  bias2_curr = bias2[:, -1]\n",
        "  bias3_curr = bias3[:, -1]\n",
        "  bias4_curr = bias4[:, -1]\n",
        "  bias5_curr = bias5[:, -1]\n",
        "  bias6_curr = bias6[:, -1]\n",
        "  bias7_curr = bias7[:, -1]\n",
        "  bias8_curr = bias8[:, -1]\n",
        "\n",
        "  out = X.reshape(-1, 3, 227, 227)\n",
        "\n",
        "    # Convolutional Layers\n",
        "\n",
        "  out = F.conv2d(out, weight1_curr, bias1_curr, 4)\n",
        "  out = F.relu(out)\n",
        "\n",
        "  out = F.max_pool2d(out, 3, 2)\n",
        "\n",
        "  out = F.conv2d(out, weight2_curr, bias2_curr, 1, 2)\n",
        "  out = F.relu(out)\n",
        "\n",
        "  out = F.max_pool2d(out, 3, 2)\n",
        "\n",
        "  out = F.conv2d(out, weight3_curr, bias3_curr, 1, 1)\n",
        "  out = F.relu(out)\n",
        "\n",
        "  out = F.conv2d(out, weight4_curr, bias4_curr, 1, 1)\n",
        "  out = F.relu(out)\n",
        "\n",
        "  out = F.conv2d(out, weight5_curr, bias5_curr, 1, 1)\n",
        "  out = F.relu(out)\n",
        "\n",
        "  out = F.max_pool2d(out, 3, 2)\n",
        "\n",
        "  out = F.dropout2d(out, 0.5, False)\n",
        "\n",
        "  # Fully connected layers\n",
        "\n",
        "  out = out.reshape(1, -1)\n",
        "\n",
        "  out = F.linear(out, weight6_curr, bias6_curr)\n",
        "  out = F.relu(out)\n",
        "  out = F.dropout(out, 0.5, False)\n",
        "  out = F.linear(out, weight7_curr, bias7_curr)\n",
        "  out = F.relu(out)\n",
        "  out = F.linear(out, weight8_curr, bias8_curr)\n",
        "  out = F.softmax(out, 1)\n",
        "\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEnRCdTcvMZV"
      },
      "outputs": [],
      "source": [
        "# Testing loop\n",
        "running_correct = 0\n",
        "total = 0\n",
        "\n",
        "for img, dom, cla in tqdm(train_dataloader) :\n",
        "  img = img.to(device)\n",
        "  dom = dom.to(device)\n",
        "  cla = cla.to(device)\n",
        "\n",
        "  pred = domainAgnosticModel(img.float())\n",
        "\n",
        "  _, pred_list = torch.max(pred, 1)\n",
        "  pred_list = pred_list.to(device)\n",
        "\n",
        "  _, cla_list = torch.max(cla, 1)\n",
        "  cla_list = cla_list.to(device)\n",
        "\n",
        "  running_correct += torch.sum(pred_list == cla_list)\n",
        "\n",
        "print(f'Accuracy of the test dataset : {running_correct/len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-ph0BSMvhvE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MLP_test.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f71267cb382aad57a1826fa66d359ca32b8120787d9413fb646158b5b727d965"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
