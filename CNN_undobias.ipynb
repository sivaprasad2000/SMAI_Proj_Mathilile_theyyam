{"cells":[{"cell_type":"markdown","metadata":{"id":"OEqL_8ZJ_Cpb"},"source":["Importing required libraries"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-LICmylKcnG8","executionInfo":{"status":"ok","timestamp":1651526901063,"user_tz":-330,"elapsed":3327,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}},"outputId":"7c0bc891-256e-4e06-ed61-29d9df83e693"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd gdrive/MyDrive/Proj"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-86n3J8tczh1","executionInfo":{"status":"ok","timestamp":1651526902877,"user_tz":-330,"elapsed":8,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}},"outputId":"d1f134a1-4e74-48ac-cc0e-cb900c079922"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Proj\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3UbZ6eQb_Cpf","executionInfo":{"status":"ok","timestamp":1651526903976,"user_tz":-330,"elapsed":536,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","import cv2\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","import copy\n","import time\n","\n","import torch\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data import random_split\n","import torchvision.transforms as transforms\n","from torchvision import models\n","from torch import optim, nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ipVqjewy_Cpg","executionInfo":{"status":"ok","timestamp":1651526903977,"user_tz":-330,"elapsed":4,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["device = 'cpu'\n","\n","if torch.cuda.is_available() :\n","    device = 'cuda'"]},{"cell_type":"markdown","metadata":{"id":"G7shgQss_Cph"},"source":["Creating dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"9g-sweAU_Cph","executionInfo":{"status":"ok","timestamp":1651526904546,"user_tz":-330,"elapsed":3,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["class ImageDataset(Dataset) :\n","\n","    def __init__(self, transform) :\n","        self.root_path = 'PACS/kfold/'\n","\n","        # Listing the domains\n","        self.domains = os.listdir(self.root_path)\n","\n","        # Listing the classes \n","        self.classes = os.listdir(self.root_path+'cartoon')\n","\n","        # Transformations\n","        self.transforms = transform\n","\n","        self.images = []\n","        self.domains_y = []\n","        self.classes_y = []\n","\n","        for i_dom, domain in enumerate(self.domains) :\n","            for i_cla, cla in enumerate(self.classes) :\n","                for image in os.listdir(self.root_path+domain+'/'+cla) :\n","                    # Finding image path\n","                    image_path = self.root_path+domain+'/'+cla+'/'+image\n","                    img = cv2.imread(image_path)\n","                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","                    self.images.append(img)\n","\n","                    # One hot encoding domain\n","                    domainVector = np.zeros(5)\n","                    domainVector[-1] = 1\n","                    domainVector[i_dom] = 1\n","                    self.domains_y.append(domainVector)\n","\n","                    # One hot encoding class\n","                    classVector = np.zeros(7)\n","                    classVector[i_cla] = 1\n","                    self.classes_y.append(classVector)\n","\n","        self.images = np.array(self.images)\n","        self.domains_y = np.array(self.domains_y)\n","        self.classes_y = np.array(self.classes_y)\n","\n","        self.domains_y = torch.Tensor(self.domains_y)\n","        self.classes_y = torch.Tensor(self.classes_y)\n","\n","    def __getitem__(self, index) :\n","\n","        return self.transforms(self.images[index].astype('float')/255), self.domains_y[index], self.classes_y[index]\n","\n","    def __len__(self) :\n","        return len(self.images)"]},{"cell_type":"markdown","metadata":{"id":"6vO8Fkkp_Cpi"},"source":["Defining transforms"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"XKU6oKSD_Cpi","executionInfo":{"status":"ok","timestamp":1651526905645,"user_tz":-330,"elapsed":6,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"YXNEoG3e_Cpj","executionInfo":{"status":"ok","timestamp":1651526943305,"user_tz":-330,"elapsed":37287,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["dataset = ImageDataset(transform=transform)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"NA1wbAYz_Cpj","executionInfo":{"status":"ok","timestamp":1651526943307,"user_tz":-330,"elapsed":41,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["# Train and test split\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [6000, 1000, 2991])"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"YWttx5bv_Cpk","executionInfo":{"status":"ok","timestamp":1651526943307,"user_tz":-330,"elapsed":38,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["train_dataloader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)\n","val_dataloader = DataLoader(dataset=val_dataset, batch_size=4, shuffle=True)\n","test_dataloader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Ef9NApY7_Cpl","executionInfo":{"status":"ok","timestamp":1651526943308,"user_tz":-330,"elapsed":37,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["dataloaders = {\n","    'train' : train_dataloader,\n","    'val' : val_dataloader,\n","    'test' : test_dataloader\n","}\n","\n","dataset_sizes = {\n","    'train' : 6000,\n","    'val': 1000,\n","    'test' : 2991\n","}"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"b-ZlI2REcmN2","executionInfo":{"status":"ok","timestamp":1651526943308,"user_tz":-330,"elapsed":36,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["def getWeightsAndBiasesCNN(in_dim, out_dim, kernel_size, no_domains) :\n","\n","    weights = torch.zeros(out_dim, in_dim, kernel_size, kernel_size, no_domains+1)\n","    biases = torch.zeros(out_dim, no_domains+1)\n","\n","    for i in range(no_domains+1) :\n","        conv_layer = nn.Conv2d(in_dim, out_dim, kernel_size)\n","\n","        weights[:, :, :, :, i] = conv_layer.state_dict()['weight']\n","        biases[:, i] = conv_layer.state_dict()['bias']\n","    \n","    return weights, biases"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"mFUgTwFbcmN2","executionInfo":{"status":"ok","timestamp":1651526943308,"user_tz":-330,"elapsed":34,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["def getWeightsAndBiasesDense(in_size, out_size, no_domains) :\n","\n","    weight_mat = torch.zeros(out_size, in_size, no_domains+1)\n","    bias_mat = torch.zeros(out_size, no_domains+1)\n","\n","    for i in range(no_domains+1) :\n","        linMod = nn.Linear(in_size, out_size)\n","\n","        weight = linMod.weight.detach()\n","        bias = linMod.bias.detach()\n","\n","        if not(i == no_domains) :\n","          weight_mat[:, :, i] = weight/no_domains\n","          bias_mat[:, i] = bias/no_domains\n","\n","    return weight_mat, bias_mat"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"WLTkNjo-_Cpm","executionInfo":{"status":"ok","timestamp":1651526949902,"user_tz":-330,"elapsed":6627,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["# Initializing the weights and biases\n","\n","weight1, bias1 = getWeightsAndBiasesCNN(3, 96, 11, 4)\n","\n","# Maxpool here\n","\n","weight2, bias2 = getWeightsAndBiasesCNN(96, 256, 5, 4)\n","\n","# Maxpool here\n","\n","weight3, bias3 = getWeightsAndBiasesCNN(256, 384, 3, 4)\n","weight4, bias4 = getWeightsAndBiasesCNN(384, 384, 3, 4)\n","weight5, bias5 = getWeightsAndBiasesCNN(384, 256, 3, 4)\n","\n","# Maxpool here\n","# Dropout here\n","\n","weight6, bias6 = getWeightsAndBiasesDense(256*6*6, 4096, 4)\n","\n","# Dropout here\n","\n","weight7, bias7 = getWeightsAndBiasesDense(4096, 4096, 4)\n","weight8, bias8 = getWeightsAndBiasesDense(4096, 7, 4)\n","\n","weight1 = weight1.to(device)\n","weight2 = weight2.to(device)\n","weight3 = weight3.to(device)\n","weight4 = weight4.to(device)\n","weight5 = weight5.to(device)\n","weight6 = weight6.to(device)\n","weight7 = weight7.to(device)\n","weight8 = weight8.to(device)\n","\n","bias1 = bias1.to(device)\n","bias2 = bias2.to(device)\n","bias3 = bias3.to(device)\n","bias4 = bias4.to(device)\n","bias5 = bias5.to(device)\n","bias6 = bias6.to(device)\n","bias7 = bias7.to(device)\n","bias8 = bias8.to(device)\n","\n","weight1.requires_grad = True\n","weight2.requires_grad = True\n","weight3.requires_grad = True\n","weight4.requires_grad = True\n","weight5.requires_grad = True\n","weight6.requires_grad = True\n","weight7.requires_grad = True\n","weight8.requires_grad = True\n","\n","bias1.requires_grad = True\n","bias2.requires_grad = True\n","bias3.requires_grad = True\n","bias4.requires_grad = True\n","bias5.requires_grad = True\n","bias6.requires_grad = True\n","bias7.requires_grad = True\n","bias8.requires_grad = True"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"DJW4Obmy_Cpm","executionInfo":{"status":"ok","timestamp":1651526949903,"user_tz":-330,"elapsed":41,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["def CNNModelUndoBias(X, dom_vec, isTraining) :\n","\n","    # Using AlexNet architecture here\n","\n","    # Calculating the current weights and biases by taking inner product\n","    weight1_curr = torch.inner(weight1, dom_vec)\n","    weight2_curr = torch.inner(weight2, dom_vec)\n","    weight3_curr = torch.inner(weight3, dom_vec)\n","    weight4_curr = torch.inner(weight4, dom_vec)\n","    weight5_curr = torch.inner(weight5, dom_vec)\n","    weight6_curr = torch.inner(weight6, dom_vec)\n","    weight7_curr = torch.inner(weight7, dom_vec)\n","    weight8_curr = torch.inner(weight8, dom_vec)\n","\n","    bias1_curr = torch.inner(bias1, dom_vec)\n","    bias2_curr = torch.inner(bias2, dom_vec)\n","    bias3_curr = torch.inner(bias3, dom_vec)\n","    bias4_curr = torch.inner(bias4, dom_vec)\n","    bias5_curr = torch.inner(bias5, dom_vec)\n","    bias6_curr = torch.inner(bias6, dom_vec)\n","    bias7_curr = torch.inner(bias7, dom_vec)\n","    bias8_curr = torch.inner(bias8, dom_vec)\n","\n","    out = X.reshape(-1, 3, 227, 227)\n","\n","    # Convolutional Layers\n","\n","    out = F.conv2d(out, weight1_curr, bias1_curr, 4)\n","    out = F.relu(out)\n","\n","    out = F.max_pool2d(out, 3, 2)\n","\n","    out = F.conv2d(out, weight2_curr, bias2_curr, 1, 2)\n","    out = F.relu(out)\n","\n","    out = F.max_pool2d(out, 3, 2)\n","\n","    out = F.conv2d(out, weight3_curr, bias3_curr, 1, 1)\n","    out = F.relu(out)\n","\n","    out = F.conv2d(out, weight4_curr, bias4_curr, 1, 1)\n","    out = F.relu(out)\n","\n","    out = F.conv2d(out, weight5_curr, bias5_curr, 1, 1)\n","    out = F.relu(out)\n","\n","    out = F.max_pool2d(out, 3, 2)\n","\n","    out = F.dropout2d(out, 0.5, isTraining)\n","\n","    # Fully connected layers\n","\n","    out = out.reshape(1, -1)\n","\n","    out = F.linear(out, weight6_curr, bias6_curr)\n","    out = F.relu(out)\n","    out = F.dropout(out, 0.5, isTraining)\n","    out = F.linear(out, weight7_curr, bias7_curr)\n","    out = F.relu(out)\n","    out = F.linear(out, weight8_curr, bias8_curr)\n","    out = F.softmax(out, 1)\n","\n","    return out"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dnN89NlF_Cpn","outputId":"e3b6d4ce-3eb6-4b01-f672-140172100b3a","executionInfo":{"status":"ok","timestamp":1651531537350,"user_tz":-330,"elapsed":4587485,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 6000/6000 [07:37<00:00, 13.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0/9 | Loss : 1.944976568222046 | Accuracy : 0.17916666666666667\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6000/6000 [07:38<00:00, 13.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/9 | Loss : 1.940592646598816 | Accuracy : 0.18483333333333332\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6000/6000 [07:38<00:00, 13.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/9 | Loss : 1.92826247215271 | Accuracy : 0.201\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6000/6000 [07:39<00:00, 13.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/9 | Loss : 1.926134467124939 | Accuracy : 0.2145\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6000/6000 [07:39<00:00, 13.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/9 | Loss : 1.9227010011672974 | Accuracy : 0.20883333333333334\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6000/6000 [07:39<00:00, 13.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/9 | Loss : 1.9198139905929565 | Accuracy : 0.2105\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6000/6000 [07:38<00:00, 13.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/9 | Loss : 1.9057163000106812 | Accuracy : 0.22583333333333333\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6000/6000 [07:38<00:00, 13.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/9 | Loss : 1.8733018636703491 | Accuracy : 0.25516666666666665\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6000/6000 [07:38<00:00, 13.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/9 | Loss : 1.8437268733978271 | Accuracy : 0.27416666666666667\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6000/6000 [07:38<00:00, 13.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/9 | Loss : 1.815737247467041 | Accuracy : 0.29833333333333334\n"]}],"source":["epochs = 10\n","lr = 0.001\n","\n","# Writing the training loop\n","for e in range(epochs) :\n","\n","    running_loss = 0.0\n","    running_correct = 0\n","    \n","    for img, dom, cla in tqdm(train_dataset) :\n","\n","        img = img.to(device)\n","        dom = dom.to(device)\n","        cla = cla.to(device)\n","        \n","        # Finding prediction\n","        pred = CNNModelUndoBias(img.float(), dom.float(), True)\n","\n","        # Calculating loss\n","        loss = F.cross_entropy(pred, cla.reshape(-1, 7))\n","\n","        running_loss += loss\n","\n","        pred_class = torch.argmax(pred)\n","        actual_class = torch.argmax(cla)\n","\n","        if(pred_class == actual_class) :\n","            running_correct += 1\n","\n","        loss.backward()\n","\n","        # Gradient descent\n","        with torch.no_grad():\n","            \n","            weight1 -= weight1.grad * lr\n","            weight2 -= weight2.grad * lr\n","            weight3 -= weight3.grad * lr\n","            weight4 -= weight4.grad * lr\n","            weight5 -= weight5.grad * lr\n","            weight6 -= weight6.grad * lr\n","            weight7 -= weight7.grad * lr\n","            weight8 -= weight8.grad * lr\n","\n","            bias1 -= bias1.grad * lr\n","            bias2 -= bias2.grad * lr\n","            bias3 -= bias3.grad * lr\n","            bias4 -= bias4.grad * lr\n","            bias5 -= bias5.grad * lr\n","            bias6 -= bias6.grad * lr\n","            bias7 -= bias7.grad * lr\n","            bias8 -= bias8.grad * lr\n","\n","            weight1.grad.zero_()\n","            weight2.grad.zero_()\n","            weight3.grad.zero_()\n","            weight4.grad.zero_()\n","            weight5.grad.zero_()\n","            weight6.grad.zero_()\n","            weight7.grad.zero_()\n","            weight8.grad.zero_()\n","\n","            bias1.grad.zero_()\n","            bias2.grad.zero_()\n","            bias3.grad.zero_()\n","            bias4.grad.zero_()\n","            bias5.grad.zero_()\n","            bias6.grad.zero_()\n","            bias7.grad.zero_()\n","            bias8.grad.zero_()\n","        \n","    print(f'Epoch {e}/{epochs-1} | Loss : {running_loss/len(train_dataset)} | Accuracy : {running_correct/len(train_dataset)}')\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"I193brBx_kw2","executionInfo":{"status":"ok","timestamp":1651531537351,"user_tz":-330,"elapsed":8,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}}},"outputs":[],"source":["# Now extracting the domain agnostic model\n","def domainAgnosticModel(X) :\n","\n","  # Calculating the current weights and biases by taking inner product\n","  weight1_curr = weight1[:, :, :, :, -1]\n","  weight2_curr = weight2[:, :, :, :, -1]\n","  weight3_curr = weight3[:, :, :, :, -1]\n","  weight4_curr = weight4[:, :, :, :, -1]\n","  weight5_curr = weight5[:, :, :, :, -1]\n","  weight6_curr = weight6[:, :, -1]\n","  weight7_curr = weight7[:, :, -1]\n","  weight8_curr = weight8[:, :, -1]\n","\n","  bias1_curr = bias1[:, -1]\n","  bias2_curr = bias2[:, -1]\n","  bias3_curr = bias3[:, -1]\n","  bias4_curr = bias4[:, -1]\n","  bias5_curr = bias5[:, -1]\n","  bias6_curr = bias6[:, -1]\n","  bias7_curr = bias7[:, -1]\n","  bias8_curr = bias8[:, -1]\n","\n","  out = X.reshape(-1, 3, 227, 227)\n","\n","    # Convolutional Layers\n","\n","  out = F.conv2d(out, weight1_curr, bias1_curr, 4)\n","  out = F.relu(out)\n","\n","  out = F.max_pool2d(out, 3, 2)\n","\n","  out = F.conv2d(out, weight2_curr, bias2_curr, 1, 2)\n","  out = F.relu(out)\n","\n","  out = F.max_pool2d(out, 3, 2)\n","\n","  out = F.conv2d(out, weight3_curr, bias3_curr, 1, 1)\n","  out = F.relu(out)\n","\n","  out = F.conv2d(out, weight4_curr, bias4_curr, 1, 1)\n","  out = F.relu(out)\n","\n","  out = F.conv2d(out, weight5_curr, bias5_curr, 1, 1)\n","  out = F.relu(out)\n","\n","  out = F.max_pool2d(out, 3, 2)\n","\n","  out = F.dropout2d(out, 0.5, False)\n","\n","  # Fully connected layers\n","  batch_size = 4\n","\n","  out = out.reshape(batch_size, -1)\n","\n","  out = F.linear(out, weight6_curr, bias6_curr)\n","  out = F.relu(out)\n","  out = F.dropout(out, 0.5, False)\n","  out = F.linear(out, weight7_curr, bias7_curr)\n","  out = F.relu(out)\n","  out = F.linear(out, weight8_curr, bias8_curr)\n","  out = F.softmax(out, 1)\n","\n","  return out"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"EEnRCdTcvMZV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651531562756,"user_tz":-330,"elapsed":25412,"user":{"displayName":"Thrivikraman pilla","userId":"04944107212256803663"}},"outputId":"519147c2-1fd9-499a-8bcc-9539246cf6df"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1500/1500 [00:25<00:00, 59.92it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy of the test dataset : 0.3095954358577728\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# Testing loop\n","running_correct = 0\n","total = 0\n","\n","for img, dom, cla in tqdm(train_dataloader) :\n","  img = img.to(device)\n","  dom = dom.to(device)\n","  cla = cla.to(device)\n","\n","  pred = domainAgnosticModel(img.float())\n","\n","  _, pred_list = torch.max(pred, 1)\n","  pred_list = pred_list.to(device)\n","\n","  _, cla_list = torch.max(cla, 1)\n","  cla_list = cla_list.to(device)\n","\n","  running_correct += torch.sum(pred_list == cla_list)\n","\n","print(f'Accuracy of the test dataset : {running_correct/len(test_dataset)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-ph0BSMvhvE"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CNN_undobias.ipynb","provenance":[]},"interpreter":{"hash":"f71267cb382aad57a1826fa66d359ca32b8120787d9413fb646158b5b727d965"},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}